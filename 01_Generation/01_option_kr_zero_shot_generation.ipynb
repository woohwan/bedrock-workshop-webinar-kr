{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Bedrock Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-east-1\n",
      "  Using profile: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n",
      "\u001b[32m\n",
      "== FM lists ==\u001b[0m\n",
      "{'Claude-Instant-V1': 'anthropic.claude-instant-v1',\n",
      " 'Claude-V1': 'anthropic.claude-v1',\n",
      " 'Claude-V2': 'anthropic.claude-v2',\n",
      " 'Command': 'cohere.command-text-v14',\n",
      " 'Jurassic-2-Mid': 'ai21.j2-mid-v1',\n",
      " 'Jurassic-2-Ultra': 'ai21.j2-ultra-v1',\n",
      " 'Titan-Embeddings-G1': 'amazon.titan-embed-text-v1',\n",
      " 'Titan-Text-G1': 'TBD'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from termcolor import colored\n",
    "from pprint import pprint\n",
    "from utils import  bedrock, print_ww\n",
    "from utils.bedrock import bedrock_info\n",
    "\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "  assumed_role = os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "  endpoint_url = os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "  region = os.environ.get(\"AWS_DEFAULT_REGION)\", None)\n",
    ")\n",
    "\n",
    "print(colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint(bedrock_info.get_list_fm_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. LangChain통합을 사용하여 Bedrock Client 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Bedrock\n",
    "\n",
    "inference_modifier = {\n",
    "  \"max_tokens_to_sample\": 4096,\n",
    "  \"temperature\": 0.5,\n",
    "  \"top_k\": 250,\n",
    "  \"top_p\": 1,\n",
    "  \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "\n",
    "textgen_llm = Bedrock(\n",
    "  model_id = \"anthropic.claude-v2\",\n",
    "  client = boto3_bedrock,\n",
    "  model_kwargs = inference_modifier,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<botocore.client.BedrockRuntime object at 0x7fcfc0e7d900>\n",
      "<botocore.client.BedrockRuntime object at 0x7fcfc0e7d900>\n"
     ]
    }
   ],
   "source": [
    "print(boto3_bedrock)\n",
    "print(textgen_llm.client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prompt 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\"\"\"Human:고객 서비스 관리자인 권율이 고객 \"이순신\"에게 메일을 작성합니다.\n",
    "이순신님은 고객 지원 엔지니어로부터 제공하는 서비스에 대해 부정적인 피드백을 받았습니다.\\n\\nAssistant:\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 안녕하세요 이순신님,\n",
      "\n",
      "저는 권율 고객 서비스 관리자입니다.\n",
      "\n",
      "이순신님께서 최근 우리 회사의 고객 지원 엔지니어로부터 받은 서비스에 대해 불만족하셨다는 소식을 들었습니다. 정말 죄송하게 생각합니다.\n",
      "\n",
      "우리 회사는 고객님의 만족을 최우선으로 생각합니다. 이순신님의 경험은 우리 서비스의 중요한 피드백이 될 것입니다.\n",
      "\n",
      "이순신님의 불편한 경험에 대해 자세히 듣고 싶습니다. 저에게 연락해 주시면, 이순신님의 의견을 경청하고 문제를 해결하기 위해 최선을 다하겠습니다.\n",
      "\n",
      "우리 회사는 고객님의 소중한 의견에 귀 기울이며, 고객님의 경험을 개선하기 위해 노력하겠습니다.\n",
      "\n",
      "감사합니다.\n",
      "\n",
      "권율 드림\n"
     ]
    }
   ],
   "source": [
    "response = textgen_llm(prompt)\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
