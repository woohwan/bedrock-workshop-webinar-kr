{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenSearch Hybrid 검색을 통한 RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bedrock Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-east-1\n",
      "  Using profile: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "from utils import bedrock\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "  assumed_role=None,\n",
    "  endpoint_url=None,\n",
    "  region='us-east-1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Titan Embedding 및 LLM Claude-v2 모델 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Bedrock\n",
    "from langchain.callbacks.stdout import StdOutCallbackHandler\n",
    "\n",
    "# Create Anthropic Model\n",
    "llm_text = Bedrock(\n",
    "  model_id = \"anthropic:cluade-v2\",\n",
    "  client = boto3_bedrock,\n",
    "  model_kwargs={\n",
    "    \"max_tokens_to_sample\": 512\n",
    "  },\n",
    "  streaming=True,\n",
    "  callbacks=[StdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Model 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import BedrockEmbeddings\n",
    "\n",
    "llm_emb = BedrockEmbeddings(\n",
    "  model_id=\"amazon.titan-embed-text-v1\",\n",
    "  client=boto3_bedrock,\n",
    "  region_name=\"us-east-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LangChain OpenSearch VectorStore 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain OpenSearch VectorStore 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opensearch info\n",
    "host = \"localhost\"\n",
    "port = 9200\n",
    "opensearch_endpoint = f\"https://{host}:{port}\"\n",
    "http_auth = (\"admin\", \"admin\")\n",
    "index_name = \"genai-demo-index-v1\"\n",
    "\n",
    "ca_certs_path = 'root-ca.pem'\n",
    "# Optional client certificates if you don't want to use HTTP basic authentication.\n",
    "client_cert_path = 'admin.pem'\n",
    "client_key_path = 'admin-key.pem'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenSearch ReIndexig\n",
    "- 기존 \"index genai-demo-index-v1\"을 \"genai-demo-index-v1-with-tokenizer\"로 \n",
    "- nori tokenizer 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenSearch Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "os_client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_compress = True, # enables gzip compression for request bodies\n",
    "    http_auth = http_auth,\n",
    "    client_cert = client_cert_path,\n",
    "    client_key = client_key_path,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False,\n",
    "    ca_certs = ca_certs_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'genai-demo-index-v1': {'aliases': {},\n",
      "                         'mappings': {'properties': {'metadata': {'properties': {'row': {'type': 'long'},\n",
      "                                                                                 'source': {'fields': {'keyword': {'ignore_above': 256,\n",
      "                                                                                                                   'type': 'keyword'}},\n",
      "                                                                                            'type': 'text'},\n",
      "                                                                                 'timestamp': {'type': 'float'},\n",
      "                                                                                 'type': {'fields': {'keyword': {'ignore_above': 256,\n",
      "                                                                                                                 'type': 'keyword'}},\n",
      "                                                                                          'type': 'text'}}},\n",
      "                                                     'text': {'fields': {'keyword': {'ignore_above': 256,\n",
      "                                                                                     'type': 'keyword'}},\n",
      "                                                              'type': 'text'},\n",
      "                                                     'vector_field': {'dimension': 1536,\n",
      "                                                                      'method': {'engine': 'nmslib',\n",
      "                                                                                 'name': 'hnsw',\n",
      "                                                                                 'parameters': {'ef_construction': 512,\n",
      "                                                                                                'm': 16},\n",
      "                                                                                 'space_type': 'l2'},\n",
      "                                                                      'type': 'knn_vector'}}},\n",
      "                         'settings': {'index': {'creation_date': '1701840733213',\n",
      "                                                'knn': 'true',\n",
      "                                                'knn.algo_param': {'ef_search': '512'},\n",
      "                                                'number_of_replicas': '1',\n",
      "                                                'number_of_shards': '1',\n",
      "                                                'provided_name': 'genai-demo-index-v1',\n",
      "                                                'replication': {'type': 'DOCUMENT'},\n",
      "                                                'uuid': 'K4LVYBDxTz-YiD5p4L4snQ',\n",
      "                                                'version': {'created': '136327927'}}}}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "index_info = os_client.indices.get(index=index_name)\n",
    "pprint(index_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'genai-demo-index-v1-with-tokenizer'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_index_name = f\"{index_name}-with-tokenizer\"\n",
    "new_index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use nori tokenizer 사용\n",
    "# analyzer_config = {\n",
    "#   \"tokenizer\": \"nori\",\n",
    "#   \"tokenizer_type\": \"nori_tokenizer\",\n",
    "#   \"char_filter\": [\"html_strip\"],\n",
    "#   \"filter\": [\"nori_number\", \"nori_readingform\", \"lowercase\"],\n",
    "#   \"decompound_mode\": \"mixed\",\n",
    "#   \"discard_punctuation\": \"true\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### index 수정: 형태소 분석기 사용 enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nori 형태소 분석기를 custom analyzer 등록\n",
    "index_info[index_name][\"settings\"][\"analysis\"] = {\n",
    "  \"tokenizer\": {\n",
    "    \"nori\": {\n",
    "      \"type\": \"nori_tokenizer\",\n",
    "      \"decompound_mode\": \"mixed\",\n",
    "      \"discard_punctuation\": \"true\"\n",
    "    }\n",
    "  },\n",
    "  \"analyzer\": {\n",
    "    \"my_analyzer\": {\n",
    "      \"type\": \"custom\",\n",
    "      \"char_filter\": [\"html_strip\"],\n",
    "      \"tokenizer\": \"nori\",\n",
    "      \"filter\": [\"nori_number\", \"nori_readingform\", \"lowercase\"]  # token filter\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# analyzer가 적용될 칼럼에 맞추어 수정\n",
    "index_info[index_name][\"mappings\"][\"properties\"][\"text\"][\"analyzer\"] = \"my_analyzer\"\n",
    "index_info[index_name]['mappings']['properties']['text']['search_analyzer'] = \"my_analyzer\"\n",
    "\n",
    "# index 설정 변경 없음\n",
    "index_info[index_name][\"settings\"][\"index\"] = {\n",
    "  \"number_of_shards\": \"5\",\n",
    "  \"knn.algo_param\": {\"ef_search\": \"512\"},\n",
    "  \"knn\": True,\n",
    "  \"number_of_replicas\": \"2\"\n",
    "}\n",
    "\n",
    "# del index alias\n",
    "# del index_info[index_name][\"aliases\"]\n",
    "new_index_info = index_info[index_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aliases': {},\n",
      " 'mappings': {'properties': {'metadata': {'properties': {'row': {'type': 'long'},\n",
      "                                                         'source': {'fields': {'keyword': {'ignore_above': 256,\n",
      "                                                                                           'type': 'keyword'}},\n",
      "                                                                    'type': 'text'},\n",
      "                                                         'timestamp': {'type': 'float'},\n",
      "                                                         'type': {'fields': {'keyword': {'ignore_above': 256,\n",
      "                                                                                         'type': 'keyword'}},\n",
      "                                                                  'type': 'text'}}},\n",
      "                             'text': {'analyzer': 'my_analyzer',\n",
      "                                      'fields': {'keyword': {'ignore_above': 256,\n",
      "                                                             'type': 'keyword'}},\n",
      "                                      'search_analyzer': 'my_analyzer',\n",
      "                                      'type': 'text'},\n",
      "                             'vector_field': {'dimension': 1536,\n",
      "                                              'method': {'engine': 'nmslib',\n",
      "                                                         'name': 'hnsw',\n",
      "                                                         'parameters': {'ef_construction': 512,\n",
      "                                                                        'm': 16},\n",
      "                                                         'space_type': 'l2'},\n",
      "                                              'type': 'knn_vector'}}},\n",
      " 'settings': {'analysis': {'analyzer': {'my_analyzer': {'char_filter': ['html_strip'],\n",
      "                                                        'filter': ['nori_number',\n",
      "                                                                   'nori_readingform',\n",
      "                                                                   'lowercase'],\n",
      "                                                        'tokenizer': 'nori',\n",
      "                                                        'type': 'custom'}},\n",
      "                           'tokenizer': {'nori': {'decompound_mode': 'mixed',\n",
      "                                                  'discard_punctuation': 'true',\n",
      "                                                  'type': 'nori_tokenizer'}}},\n",
      "              'index': {'knn': True,\n",
      "                        'knn.algo_param': {'ef_search': '512'},\n",
      "                        'number_of_replicas': '2',\n",
      "                        'number_of_shards': '5'}}}\n"
     ]
    }
   ],
   "source": [
    "pprint(new_index_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_name=genai-demo-index-v1-with-tokenizer, exists=False\n",
      "Index does not exist\n"
     ]
    }
   ],
   "source": [
    "from utils.opensearch import opensearch_utils\n",
    "\n",
    "index_exists = opensearch_utils.check_if_index_exists(os_client, new_index_name)\n",
    "if index_exists:\n",
    "    opensearch_utils.delete_index(os_client, new_index_name)\n",
    "else:\n",
    "    print(\"Index does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index\n",
    "OpenSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "vector_db = OpenSearchVectorSearch(\n",
    "  opensearch_url=opensearch_endpoint,\n",
    "  embedding_function=llm_emb,\n",
    "  index_name =index_name,\n",
    "  http_auth=http_auth,\n",
    "  is_aoss=False,\n",
    "  engine=\"faiss\",\n",
    "  space_type=\"l2\",\n",
    "  use_ssl=True,\n",
    "  verify_certs=True,\n",
    "  ssl_assert_hostname=False,\n",
    "  ssl_show_warn=False,\n",
    "  ca_certs=ca_certs_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenSearch Cleint 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
